"""Document Upload Service - Î¨∏ÏÑú ÏóÖÎ°úÎìú Î∞è Ïù∏Îç±Ïã±"""

import logging
import hashlib
import uuid
from typing import Any, Optional
from datetime import datetime

from langchain_text_splitters import RecursiveCharacterTextSplitter

from src.config import app_config as config
from src.infrastructure.database.qdrant_manager import QdrantManager
from src.services.embeddings.manager import EmbeddingManager

logger = logging.getLogger(__name__)


class DocumentUploadService:
    """Î¨∏ÏÑú ÏóÖÎ°úÎìú Î∞è Î≤°ÌÑ∞ DB Ïù∏Îç±Ïã± ÏÑúÎπÑÏä§"""
    
    def __init__(
        self,
        qdrant_manager: QdrantManager,
        embedding_manager: EmbeddingManager
    ):
        """Î¨∏ÏÑú ÏóÖÎ°úÎìú ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî"""
        self.qdrant_manager = qdrant_manager
        self.embedding_manager = embedding_manager
        
        # ÌÖçÏä§Ìä∏ Î∂ÑÌï†Í∏∞ Ï¥àÍ∏∞Ìôî
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.CHUNK_SIZE,
            chunk_overlap=config.CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", ".", "!", "?", ";", " ", ""]
        )
        
        logger.info("üìÑ Î¨∏ÏÑú ÏóÖÎ°úÎìú ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
    
    def upload_document(
        self,
        content: str,
        title: str,
        metadata: Optional[dict[str, Any]] = None,
        collection_name: Optional[str] = None
    ) -> dict[str, Any]:
        """
        Îã®Ïùº Î¨∏ÏÑú ÏóÖÎ°úÎìú Î∞è Ïù∏Îç±Ïã±
        
        Args:
            content: Î¨∏ÏÑú ÎÇ¥Ïö©
            title: Î¨∏ÏÑú Ï†úÎ™©
            metadata: Ï∂îÍ∞Ä Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
            collection_name: ÎåÄÏÉÅ Ïª¨Î†âÏÖò Ïù¥Î¶Ñ
        
        Returns:
            ÏóÖÎ°úÎìú Í≤∞Í≥º Ï†ïÎ≥¥
        """
        collection = collection_name or config.COLLECTION_NAME
        
        try:
            logger.info(f"üì§ Î¨∏ÏÑú ÏóÖÎ°úÎìú ÏãúÏûë: {title}")
            
            # Ïª¨Î†âÏÖò ÌôïÏù∏/ÏÉùÏÑ±
            if not self.qdrant_manager.collection_exists(collection):
                self.qdrant_manager.create_collection(collection)
            
            # ÌÖçÏä§Ìä∏ Î∂ÑÌï†
            chunks = self.text_splitter.split_text(content)
            logger.info(f"    Ï≤≠ÌÅ¨ Ïàò: {len(chunks)}")
            
            if not chunks:
                return {
                    "success": False,
                    "error": "Î¨∏ÏÑúÏóêÏÑú ÌÖçÏä§Ìä∏Î•º Ï∂îÏ∂úÌï† Ïàò ÏóÜÏäµÎãàÎã§",
                    "chunks_count": 0
                }
            
            # Î¨∏ÏÑú ID ÏÉùÏÑ±
            doc_id = hashlib.md5(content.encode()).hexdigest()[:16]
            
            # Í∏∞Î≥∏ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
            base_metadata = {
                "title": title,
                "document_id": doc_id,
                "uploaded_at": datetime.now().isoformat(),
                "total_chunks": len(chunks),
                **(metadata or {})
            }
            
            # Ï≤≠ÌÅ¨Î≥Ñ Ìè¨Ïù∏Ìä∏ ÏÉùÏÑ±
            points = []
            chunk_texts = []
            
            for i, chunk in enumerate(chunks):
                point_id = f"{doc_id}_{i}"
                chunk_metadata = {
                    **base_metadata,
                    "chunk_index": i,
                    "content": chunk
                }
                
                points.append({
                    "id": point_id,
                    "vector": None,  # ÎÇòÏ§ëÏóê Ï∂îÍ∞Ä
                    "payload": chunk_metadata
                })
                chunk_texts.append(chunk)
            
            # Î∞∞Ïπò ÏûÑÎ≤†Îî© ÏÉùÏÑ±
            logger.info("    ÏûÑÎ≤†Îî© ÏÉùÏÑ± Ï§ë...")
            embeddings = self.embedding_manager.create_embeddings_batch(
                chunk_texts,
                input_type="document"
            )
            
            # Î≤°ÌÑ∞ Ï∂îÍ∞Ä
            for point, embedding in zip(points, embeddings):
                point["vector"] = embedding
            
            # QdrantÏóê ÏóÖÎ°úÎìú
            logger.info("    QdrantÏóê ÏóÖÎ°úÎìú Ï§ë...")
            success = self.qdrant_manager.upsert_points(
                points=points,
                collection_name=collection,
                batch_size=config.UPLOAD_BATCH_SIZE
            )
            
            if success:
                logger.info(f"‚úÖ Î¨∏ÏÑú ÏóÖÎ°úÎìú ÏôÑÎ£å: {title} ({len(chunks)}Í∞ú Ï≤≠ÌÅ¨)")
                return {
                    "success": True,
                    "document_id": doc_id,
                    "title": title,
                    "chunks_count": len(chunks),
                    "collection": collection
                }
            else:
                return {
                    "success": False,
                    "error": "Qdrant ÏóÖÎ°úÎìú Ïã§Ìå®",
                    "chunks_count": len(chunks)
                }
            
        except Exception as e:
            logger.error(f"‚ùå Î¨∏ÏÑú ÏóÖÎ°úÎìú Ïã§Ìå®: {e}")
            return {
                "success": False,
                "error": str(e),
                "chunks_count": 0
            }
    
    def upload_documents_batch(
        self,
        documents: list[dict[str, Any]],
        collection_name: Optional[str] = None
    ) -> dict[str, Any]:
        """
        Îã§Ï§ë Î¨∏ÏÑú Î∞∞Ïπò ÏóÖÎ°úÎìú
        
        Args:
            documents: Î¨∏ÏÑú Î™©Î°ù [{"content": str, "title": str, "metadata": dict}, ...]
            collection_name: ÎåÄÏÉÅ Ïª¨Î†âÏÖò Ïù¥Î¶Ñ
        
        Returns:
            ÏóÖÎ°úÎìú Í≤∞Í≥º ÏöîÏïΩ
        """
        results = {
            "total": len(documents),
            "success": 0,
            "failed": 0,
            "details": []
        }
        
        for doc in documents:
            result = self.upload_document(
                content=doc.get("content", ""),
                title=doc.get("title", "Untitled"),
                metadata=doc.get("metadata"),
                collection_name=collection_name
            )
            
            if result.get("success"):
                results["success"] += 1
            else:
                results["failed"] += 1
            
            results["details"].append(result)
        
        logger.info(f"üì¶ Î∞∞Ïπò ÏóÖÎ°úÎìú ÏôÑÎ£å: {results['success']}/{results['total']} ÏÑ±Í≥µ")
        return results
    
    def delete_document(
        self,
        document_id: str,
        collection_name: Optional[str] = None
    ) -> bool:
        """Î¨∏ÏÑú ÏÇ≠Ï†ú (Î™®Îì† Ï≤≠ÌÅ¨ ÏÇ≠Ï†ú)"""
        collection = collection_name or config.COLLECTION_NAME
        
        try:
            # Î¨∏ÏÑú IDÎ°ú Î™®Îì† Ï≤≠ÌÅ¨ Ìè¨Ïù∏Ìä∏ ID Ï°∞Ìöå
            # document_id ÌïÑÌÑ∞Î°ú Í≤ÄÏÉâ
            from qdrant_client.http import models
            
            # Ïä§ÌÅ¨Î°§Î°ú Î™®Îì† Ìè¨Ïù∏Ìä∏ Ï°∞Ìöå
            points, _ = self.qdrant_manager.client.scroll(
                collection_name=collection,
                scroll_filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="document_id",
                            match=models.MatchValue(value=document_id)
                        )
                    ]
                ),
                limit=1000,
                with_payload=False
            )
            
            if not points:
                logger.warning(f"Î¨∏ÏÑúÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏùå: {document_id}")
                return False
            
            point_ids = [str(p.id) for p in points]
            
            success = self.qdrant_manager.delete_points(point_ids, collection)
            if success:
                logger.info(f"‚úÖ Î¨∏ÏÑú ÏÇ≠Ï†ú ÏôÑÎ£å: {document_id} ({len(point_ids)}Í∞ú Ï≤≠ÌÅ¨)")
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Î¨∏ÏÑú ÏÇ≠Ï†ú Ïã§Ìå®: {e}")
            return False
    
    def get_document_info(
        self,
        document_id: str,
        collection_name: Optional[str] = None
    ) -> Optional[dict[str, Any]]:
        """Î¨∏ÏÑú Ï†ïÎ≥¥ Ï°∞Ìöå"""
        collection = collection_name or config.COLLECTION_NAME
        
        try:
            from qdrant_client.http import models
            
            # Î¨∏ÏÑúÏùò Ï≤´ Î≤àÏß∏ Ï≤≠ÌÅ¨ Ï°∞Ìöå
            points, _ = self.qdrant_manager.client.scroll(
                collection_name=collection,
                scroll_filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="document_id",
                            match=models.MatchValue(value=document_id)
                        )
                    ]
                ),
                limit=1,
                with_payload=True
            )
            
            if not points:
                return None
            
            payload = points[0].payload
            return {
                "document_id": document_id,
                "title": payload.get("title", ""),
                "total_chunks": payload.get("total_chunks", 0),
                "uploaded_at": payload.get("uploaded_at", ""),
                "metadata": {
                    k: v for k, v in payload.items()
                    if k not in ["content", "title", "document_id", "chunk_index", "total_chunks", "uploaded_at"]
                }
            }
            
        except Exception as e:
            logger.error(f"Î¨∏ÏÑú Ï†ïÎ≥¥ Ï°∞Ìöå Ïã§Ìå®: {e}")
            return None

