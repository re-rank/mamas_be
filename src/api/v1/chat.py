"""Chat API - RAG ê¸°ë°˜ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""

import logging
from typing import Any, Optional
from datetime import datetime

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

from src.config import app_config as config
from src.infrastructure.database.qdrant_manager import QdrantManager
from src.services.embeddings.manager import EmbeddingManager
from src.services.search.search_service import SearchService
from src.services.llm.handler import LLMHandler

logger = logging.getLogger(__name__)

router = APIRouter()


# ì˜ì¡´ì„± ì£¼ì…ì„ ìœ„í•œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_qdrant_manager: Optional[QdrantManager] = None
_embedding_manager: Optional[EmbeddingManager] = None
_search_service: Optional[SearchService] = None
_llm_handler: Optional[LLMHandler] = None


def get_qdrant_manager() -> QdrantManager:
    """Qdrant ë§¤ë‹ˆì € ì˜ì¡´ì„±"""
    global _qdrant_manager
    if _qdrant_manager is None:
        _qdrant_manager = QdrantManager()
    return _qdrant_manager


def get_embedding_manager() -> EmbeddingManager:
    """ì„ë² ë”© ë§¤ë‹ˆì € ì˜ì¡´ì„±"""
    global _embedding_manager
    if _embedding_manager is None:
        _embedding_manager = EmbeddingManager()
    return _embedding_manager


def get_search_service() -> SearchService:
    """ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì˜ì¡´ì„±"""
    global _search_service
    if _search_service is None:
        _search_service = SearchService(
            qdrant_manager=get_qdrant_manager(),
            embedding_manager=get_embedding_manager()
        )
    return _search_service


def get_llm_handler() -> LLMHandler:
    """LLM í•¸ë“¤ëŸ¬ ì˜ì¡´ì„±"""
    global _llm_handler
    if _llm_handler is None:
        _llm_handler = LLMHandler()
    return _llm_handler


# Request/Response ëª¨ë¸
class ChatMessage(BaseModel):
    """ì±„íŒ… ë©”ì‹œì§€"""
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user/assistant)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")


class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­"""
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€", min_length=1)
    conversation_history: list[ChatMessage] = Field(
        default=[],
        description="ëŒ€í™” ê¸°ë¡"
    )
    top_k: int = Field(
        default=5,
        ge=1,
        le=20,
        description="ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜"
    )
    temperature: float = Field(
        default=0.7,
        ge=0.0,
        le=2.0,
        description="LLM ì˜¨ë„"
    )
    collection_name: Optional[str] = Field(
        default=None,
        description="ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ ì´ë¦„"
    )
    stream: bool = Field(
        default=False,
        description="ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—¬ë¶€"
    )


class SearchResult(BaseModel):
    """ê²€ìƒ‰ ê²°ê³¼"""
    id: str
    score: float
    rank: int
    content: str
    title: str
    metadata: dict[str, Any] = {}


class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ"""
    answer: str = Field(..., description="AI ì‘ë‹µ")
    search_results: list[SearchResult] = Field(
        default=[],
        description="ê²€ìƒ‰ ê²°ê³¼"
    )
    model: str = Field(default="", description="ì‚¬ìš©ëœ LLM ëª¨ë¸")
    usage: dict[str, int] = Field(
        default={},
        description="í† í° ì‚¬ìš©ëŸ‰"
    )
    success: bool = Field(default=True, description="ì„±ê³µ ì—¬ë¶€")
    timestamp: str = Field(
        default_factory=lambda: datetime.now().isoformat(),
        description="ì‘ë‹µ ì‹œê°„"
    )


class SearchRequest(BaseModel):
    """ê²€ìƒ‰ ìš”ì²­"""
    query: str = Field(..., description="ê²€ìƒ‰ ì¿¼ë¦¬", min_length=1)
    top_k: int = Field(default=5, ge=1, le=20, description="ê²€ìƒ‰ ê²°ê³¼ ìˆ˜")
    collection_name: Optional[str] = Field(default=None, description="ì»¬ë ‰ì…˜ ì´ë¦„")
    filters: dict[str, Any] = Field(default={}, description="í•„í„° ì¡°ê±´")


class SearchResponse(BaseModel):
    """ê²€ìƒ‰ ì‘ë‹µ"""
    results: list[SearchResult]
    total: int
    query: str
    timestamp: str = Field(
        default_factory=lambda: datetime.now().isoformat()
    )


# API ì—”ë“œí¬ì¸íŠ¸
@router.post("/chat", response_model=ChatResponse, tags=["chat"])
async def chat(
    request: ChatRequest,
    search_service: SearchService = Depends(get_search_service),
    llm_handler: LLMHandler = Depends(get_llm_handler)
):
    """
    RAG ê¸°ë°˜ ì±„íŒ… API
    
    1. ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ LLM ë‹µë³€ ìƒì„±
    """
    try:
        logger.info(f"ğŸ“¨ ì±„íŒ… ìš”ì²­: '{request.message[:50]}...'")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        if request.stream:
            return StreamingResponse(
                _stream_chat_response(request, search_service, llm_handler),
                media_type="text/event-stream"
            )

        # ê²€ìƒ‰ ìˆ˜í–‰ (ë©€í‹° ì»¬ë ‰ì…˜ ê²€ìƒ‰)
        search_results = _perform_search(request, search_service)

        # ëŒ€í™” ê¸°ë¡ ë³€í™˜
        history = [
            {"role": msg.role, "content": msg.content}
            for msg in request.conversation_history
        ]
        
        # ë‹µë³€ ìƒì„±
        result = llm_handler.generate_answer(
            question=request.message,
            search_results=search_results,
            conversation_history=history,
            temperature=request.temperature
        )
        
        # ì‘ë‹µ êµ¬ì„±
        return ChatResponse(
            answer=result.get("answer", ""),
            search_results=[
                SearchResult(
                    id=r.get("id", ""),
                    score=r.get("score", 0.0),
                    rank=r.get("rank", 0),
                    content=r.get("content", ""),
                    title=r.get("title", ""),
                    metadata=r.get("metadata", {})
                )
                for r in search_results
            ],
            model=result.get("model", ""),
            usage=result.get("usage", {}),
            success=result.get("success", True)
        )
        
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _perform_search(request: ChatRequest, search_service: SearchService) -> list[dict]:
    """ë©€í‹° ì»¬ë ‰ì…˜ ê²€ìƒ‰ ìˆ˜í–‰"""
    if request.collection_name:
        # íŠ¹ì • ì»¬ë ‰ì…˜ ì§€ì • ì‹œ í•´ë‹¹ ì»¬ë ‰ì…˜ë§Œ ê²€ìƒ‰
        return search_service.search(
            query=request.message,
            top_k=request.top_k,
            collection_name=request.collection_name
        )

    # ê¸°ë³¸: ëª¨ë“  ì„¤ì •ëœ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
    multi_results = search_service.multi_collection_search(
        query=request.message,
        collection_names=config.SEARCH_COLLECTIONS,
        top_k=request.top_k
    )

    # ëª¨ë“  ì»¬ë ‰ì…˜ ê²°ê³¼ë¥¼ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë³‘í•©
    all_results = []
    for collection_name, results in multi_results.items():
        for r in results:
            r["collection"] = collection_name
        all_results.extend(results)

    # ì ìˆ˜ìˆœ ì •ë ¬ í›„ top_kê°œ ì„ íƒ
    all_results.sort(key=lambda x: x.get("score", 0), reverse=True)
    search_results = all_results[:request.top_k]

    # rank ì¬í• ë‹¹
    for i, r in enumerate(search_results):
        r["rank"] = i + 1

    logger.info(f"ğŸ“Š ë©€í‹° ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
    return search_results


async def _stream_chat_response(
    request: ChatRequest,
    search_service: SearchService,
    llm_handler: LLMHandler
):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±ê¸°"""
    try:
        # ê²€ìƒ‰ ìˆ˜í–‰ (ë©€í‹° ì»¬ë ‰ì…˜ ê²€ìƒ‰)
        search_results = _perform_search(request, search_service)

        history = [
            {"role": msg.role, "content": msg.content}
            for msg in request.conversation_history
        ]
        
        # ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„±
        for chunk in llm_handler.generate_answer_stream(
            question=request.message,
            search_results=search_results,
            conversation_history=history,
            temperature=request.temperature
        ):
            yield f"data: {chunk}\n\n"
        
        yield "data: [DONE]\n\n"
        
    except Exception as e:
        yield f"data: [ERROR] {str(e)}\n\n"


@router.post("/search", response_model=SearchResponse, tags=["search"])
async def search(
    request: SearchRequest,
    search_service: SearchService = Depends(get_search_service)
):
    """
    ë²¡í„° ê²€ìƒ‰ API
    
    ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    try:
        logger.info(f"ğŸ” ê²€ìƒ‰ ìš”ì²­: '{request.query[:50]}...'")
        
        if request.filters:
            results = search_service.search_with_filter(
                query=request.query,
                filters=request.filters,
                top_k=request.top_k,
                collection_name=request.collection_name
            )
        else:
            results = search_service.search(
                query=request.query,
                top_k=request.top_k,
                collection_name=request.collection_name
            )
        
        return SearchResponse(
            results=[
                SearchResult(
                    id=r.get("id", ""),
                    score=r.get("score", 0.0),
                    rank=r.get("rank", 0),
                    content=r.get("content", ""),
                    title=r.get("title", ""),
                    metadata=r.get("metadata", {})
                )
                for r in results
            ],
            total=len(results),
            query=request.query
        )
        
    except Exception as e:
        logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/health", tags=["health"])
async def health_check(
    qdrant_manager: QdrantManager = Depends(get_qdrant_manager)
):
    """í—¬ìŠ¤ ì²´í¬ API"""
    try:
        collections = qdrant_manager.list_collections()
        return {
            "status": "healthy",
            "service": "MAMAS RAG API",
            "qdrant_connected": True,
            "collections_count": len(collections),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "service": "MAMAS RAG API",
            "qdrant_connected": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


@router.get("/collections", tags=["admin"])
async def list_collections(
    qdrant_manager: QdrantManager = Depends(get_qdrant_manager)
):
    """ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ API"""
    try:
        collections = qdrant_manager.list_collections()
        collection_info = []
        
        for name in collections:
            info = qdrant_manager.get_collection_info(name)
            if info:
                collection_info.append(info)
        
        return {
            "collections": collection_info,
            "total": len(collections)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/cache", tags=["admin"])
async def clear_cache(
    search_service: SearchService = Depends(get_search_service)
):
    """ê²€ìƒ‰ ìºì‹œ ì´ˆê¸°í™” API"""
    try:
        search_service.clear_cache()
        return {"message": "ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤", "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

