"""
ê³µì¸ë…¸ë¬´ì‚¬ PDF ìë£Œ ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸
- OCRëœ PDFì™€ OCR ì•ˆëœ PDF ëª¨ë‘ ì²˜ë¦¬
- Voyage AIë¡œ ì„ë² ë”© ìƒì„±
- Qdrantì— ì €ì¥
"""

import os
import sys
import uuid
import hashlib
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / ".env")

# PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import pymupdf  # PyMuPDF (fitz)
except ImportError:
    import fitz as pymupdf

try:
    import pytesseract
    from PIL import Image
    import io
    # Windows Tesseract ê²½ë¡œ ì„¤ì •
    TESSERACT_PATH = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
    if os.path.exists(TESSERACT_PATH):
        pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("âš ï¸ pytesseract ë˜ëŠ” Pillowê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - OCR ê¸°ëŠ¥ ë¹„í™œì„±í™”")

# í…ìŠ¤íŠ¸ ë¶„í• 
from langchain_text_splitters import RecursiveCharacterTextSplitter

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from src.services.embeddings.manager import EmbeddingManager
from src.infrastructure.database.qdrant_manager import QdrantManager
from src.config import app_config as config

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(PROJECT_ROOT / "logs" / "pdf_embedding.log", encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class PDFEmbedder:
    """PDF ë¬¸ì„œ ì„ë² ë”© ì²˜ë¦¬ê¸°"""

    def __init__(
        self,
        collection_name: str = "labor_consultant_docs",
        chunk_size: int = 1000,
        chunk_overlap: int = 200
    ):
        """
        ì´ˆê¸°í™”

        Args:
            collection_name: Qdrant ì»¬ë ‰ì…˜ ì´ë¦„
            chunk_size: ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)
            chunk_overlap: ì²­í¬ ì˜¤ë²„ë© (ë¬¸ì ìˆ˜)
        """
        self.collection_name = collection_name
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )

        # ì„ë² ë”© ë§¤ë‹ˆì €
        logger.info("ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        self.embedding_manager = EmbeddingManager()

        # Qdrant ë§¤ë‹ˆì €
        logger.info("Qdrant ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        self.qdrant_manager = QdrantManager()

        # ì»¬ë ‰ì…˜ ìƒì„± (ì—†ìœ¼ë©´)
        self._ensure_collection()

        logger.info(f"âœ… PDFEmbedder ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   ì»¬ë ‰ì…˜: {self.collection_name}")
        logger.info(f"   ì²­í¬ í¬ê¸°: {chunk_size}")
        logger.info(f"   ì˜¤ë²„ë©: {chunk_overlap}")

    def _ensure_collection(self):
        """ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸ ë° ìƒì„±"""
        if not self.qdrant_manager.collection_exists(self.collection_name):
            self.qdrant_manager.create_collection(
                collection_name=self.collection_name,
                vector_size=self.embedding_manager.dimension
            )
            logger.info(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„±ë¨")
        else:
            logger.info(f"â„¹ï¸ ì»¬ë ‰ì…˜ '{self.collection_name}' ì´ë¯¸ ì¡´ì¬")

    def extract_text_from_pdf(self, pdf_path: Path, show_progress: bool = True) -> tuple[str, dict]:
        """
        PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR í¬í•¨)

        Returns:
            tuple: (ì¶”ì¶œëœ í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°)
        """
        pdf_path = Path(pdf_path)
        text_parts = []
        metadata = {
            "file_name": pdf_path.name,
            "file_path": str(pdf_path),
            "page_count": 0,
            "ocr_used": False,
            "extraction_method": "text",
            "ocr_pages": 0
        }

        try:
            doc = pymupdf.open(str(pdf_path))
            metadata["page_count"] = len(doc)
            total_pages = len(doc)

            # í˜ì´ì§€ë³„ ì§„í–‰ë¥  í‘œì‹œ
            page_iterator = tqdm(
                enumerate(doc),
                total=total_pages,
                desc=f"  í˜ì´ì§€ ì¶”ì¶œ",
                leave=False,
                disable=not show_progress
            )

            for page_num, page in page_iterator:
                # ë¨¼ì € í…ìŠ¤íŠ¸ ì§ì ‘ ì¶”ì¶œ ì‹œë„
                text = page.get_text("text")

                # í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´ OCR ì‹œë„
                if len(text.strip()) < 50 and OCR_AVAILABLE:
                    page_iterator.set_postfix({"OCR": f"p.{page_num + 1}"})
                    ocr_text = self._ocr_page(page)
                    if ocr_text:
                        text = ocr_text
                        metadata["ocr_used"] = True
                        metadata["extraction_method"] = "ocr"
                        metadata["ocr_pages"] += 1

                if text.strip():
                    text_parts.append(f"[í˜ì´ì§€ {page_num + 1}]\n{text}")

            doc.close()

        except Exception as e:
            logger.error(f"PDF ì½ê¸° ì‹¤íŒ¨ ({pdf_path.name}): {e}")
            raise

        full_text = "\n\n".join(text_parts)
        return full_text, metadata

    def _ocr_page(self, page) -> Optional[str]:
        """í˜ì´ì§€ OCR ì²˜ë¦¬"""
        if not OCR_AVAILABLE:
            return None

        try:
            # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í•´ìƒë„ 300 DPI)
            mat = pymupdf.Matrix(300/72, 300/72)
            pix = page.get_pixmap(matrix=mat)

            # PIL Imageë¡œ ë³€í™˜
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))

            # OCR ìˆ˜í–‰ (í•œêµ­ì–´ + ì˜ì–´)
            text = pytesseract.image_to_string(
                image,
                lang='kor+eng',
                config='--psm 1'  # ìë™ í˜ì´ì§€ ë¶„í• 
            )

            return text.strip()

        except Exception as e:
            logger.warning(f"OCR ì‹¤íŒ¨: {e}")
            return None

    def generate_doc_id(self, file_path: str, chunk_index: int) -> str:
        """ë¬¸ì„œ ì²­í¬ì˜ ê³ ìœ  ID ìƒì„±"""
        content = f"{file_path}:{chunk_index}"
        return hashlib.md5(content.encode()).hexdigest()

    def process_pdf(self, pdf_path: Path) -> int:
        """
        ë‹¨ì¼ PDF ì²˜ë¦¬ ë° ì„ë² ë”©

        Returns:
            int: ì €ì¥ëœ ì²­í¬ ìˆ˜
        """
        pdf_path = Path(pdf_path)
        logger.info(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {pdf_path.name}")

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text, metadata = self.extract_text_from_pdf(pdf_path)

        if not text.strip():
            logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ ì—†ìŒ: {pdf_path.name}")
            return 0

        logger.info(f"   ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {len(text):,}ì ({metadata['page_count']}í˜ì´ì§€)")
        if metadata["ocr_used"]:
            logger.info(f"   OCR ì‚¬ìš©ë¨: {metadata.get('ocr_pages', 0)}í˜ì´ì§€")

        # í…ìŠ¤íŠ¸ ë¶„í• 
        chunks = self.text_splitter.split_text(text)
        logger.info(f"   ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")

        if not chunks:
            return 0

        # ì„ë² ë”© ìƒì„± (ë°°ì¹˜)
        logger.info(f"   ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.embedding_manager.create_embeddings_batch(
            texts=chunks,
            input_type="document"
        )

        # í¬ì¸íŠ¸ ìƒì„±
        points = []
        for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
            point_id = self.generate_doc_id(str(pdf_path), i)

            payload = {
                "text": chunk,
                "source": pdf_path.name,
                "file_path": str(pdf_path),
                "chunk_index": i,
                "total_chunks": len(chunks),
                "page_count": metadata["page_count"],
                "ocr_used": metadata["ocr_used"],
                "category": "ê³µì¸ë…¸ë¬´ì‚¬",
                "created_at": datetime.now().isoformat()
            }

            points.append({
                "id": point_id,
                "vector": embedding,
                "payload": payload
            })

        # Qdrantì— ì—…ë¡œë“œ
        success = self.qdrant_manager.upsert_points(
            points=points,
            collection_name=self.collection_name
        )

        if success:
            logger.info(f"   âœ… {len(points)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
            return len(points)
        else:
            logger.error(f"   âŒ ì €ì¥ ì‹¤íŒ¨")
            return 0

    def process_directory(self, dir_path: str) -> dict:
        """
        ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  PDF ì²˜ë¦¬

        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼ í†µê³„
        """
        dir_path = Path(dir_path)

        if not dir_path.exists():
            raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dir_path}")

        # PDF íŒŒì¼ ì°¾ê¸°
        pdf_files = list(dir_path.glob("**/*.pdf"))
        logger.info(f"ğŸ” ë°œê²¬ëœ PDF íŒŒì¼: {len(pdf_files)}ê°œ")

        if not pdf_files:
            logger.warning("PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return {"total": 0, "success": 0, "failed": 0, "chunks": 0}

        stats = {
            "total": len(pdf_files),
            "success": 0,
            "failed": 0,
            "chunks": 0,
            "failed_files": []
        }

        # ì§„í–‰ í‘œì‹œì™€ í•¨ê»˜ ì²˜ë¦¬
        for pdf_path in tqdm(pdf_files, desc="PDF ì²˜ë¦¬"):
            try:
                chunks = self.process_pdf(pdf_path)
                if chunks > 0:
                    stats["success"] += 1
                    stats["chunks"] += chunks
                else:
                    stats["failed"] += 1
                    stats["failed_files"].append(str(pdf_path))
            except Exception as e:
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨ ({pdf_path.name}): {e}")
                stats["failed"] += 1
                stats["failed_files"].append(str(pdf_path))

        return stats


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ê³µì¸ë…¸ë¬´ì‚¬ PDF ìë£Œ ì„ë² ë”©")
    parser.add_argument(
        "--path",
        type=str,
        default=r"C:\Users\alvin\OneDrive\ë°”íƒ• í™”ë©´\ê³µì¸ë…¸ë¬´ì‚¬ ìë£Œ",
        help="PDF íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--collection",
        type=str,
        default="labor_consultant_docs",
        help="Qdrant ì»¬ë ‰ì…˜ ì´ë¦„"
    )
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=1000,
        help="ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)"
    )
    parser.add_argument(
        "--chunk-overlap",
        type=int,
        default=200,
        help="ì²­í¬ ì˜¤ë²„ë© (ë¬¸ì ìˆ˜)"
    )

    args = parser.parse_args()

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = PROJECT_ROOT / "logs"
    log_dir.mkdir(exist_ok=True)

    print("=" * 60)
    print("ğŸš€ ê³µì¸ë…¸ë¬´ì‚¬ PDF ì„ë² ë”© ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“‚ ê²½ë¡œ: {args.path}")
    print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {args.collection}")
    print(f"ğŸ“ ì²­í¬ í¬ê¸°: {args.chunk_size}")
    print(f"ğŸ”— ì˜¤ë²„ë©: {args.chunk_overlap}")
    print(f"ğŸ§  OCR ê°€ëŠ¥: {OCR_AVAILABLE}")
    print("=" * 60)

    try:
        # PDFEmbedder ì´ˆê¸°í™”
        embedder = PDFEmbedder(
            collection_name=args.collection,
            chunk_size=args.chunk_size,
            chunk_overlap=args.chunk_overlap
        )

        path = Path(args.path)

        if path.is_file():
            # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
            chunks = embedder.process_pdf(path)
            print(f"\nâœ… ì™„ë£Œ: {chunks}ê°œ ì²­í¬ ì €ì¥")
        else:
            # ë””ë ‰í† ë¦¬ ì²˜ë¦¬
            stats = embedder.process_directory(path)

            print("\n" + "=" * 60)
            print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼")
            print("=" * 60)
            print(f"   ì „ì²´ íŒŒì¼: {stats['total']}ê°œ")
            print(f"   ì„±ê³µ: {stats['success']}ê°œ")
            print(f"   ì‹¤íŒ¨: {stats['failed']}ê°œ")
            print(f"   ì´ ì²­í¬: {stats['chunks']}ê°œ")

            if stats['failed_files']:
                print("\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼:")
                for f in stats['failed_files'][:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                    print(f"   - {f}")
                if len(stats['failed_files']) > 10:
                    print(f"   ... ì™¸ {len(stats['failed_files']) - 10}ê°œ")

        # ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
        info = embedder.qdrant_manager.get_collection_info(args.collection)
        if info:
            print(f"\nğŸ“¦ ì»¬ë ‰ì…˜ '{args.collection}' í˜„ì¬ ìƒíƒœ:")
            print(f"   ì´ í¬ì¸íŠ¸: {info['points_count']:,}ê°œ")
            print(f"   ìƒíƒœ: {info['status']}")

    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        raise


if __name__ == "__main__":
    main()
